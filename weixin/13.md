# Python多线程总结（Python2.7）

今天我们来介绍下Python的多线程。

说起Python的多线程，不得不说一下GIL（全局解释器锁），GIL并不是Python的特性，只在CPython解释器中存在，其他的解释器比如PyPy，JPython等就没有GIL的概念。因为有了全局解释器锁的存在，让CPython解释器同一时刻只有一个线程在运行，看起来就像是单线程一样。这样看来，Python的多线程好像并没什么用。其实在IO密集型的场景下，比如爬虫，Web服务等，GIL的影响时非常小的。如果时CPU密集型的程序，那使用多进程也可以避免GIL的影响，因为每个进程都有一个GIL。

Python的threading模块是对thread底层线程的封装，提供了更方便的线程相关的操作，threading模块主要有Thread, Lock, Rlock, Condition, Semaphore, Event, Timer, local这些类，今天主要介绍下Thread类。

#### threading.Thread(group=None, target=None, name=None, args=(), kwargs=None, verbose=None)

Thread类有两种使用方式：

1、通过一个需要执行的函数实例化一个Thread对象

```python
# coding: utf-8
import re
import threading
import requests

def get_page(url):
    print('start get {}'.format(url))
    resp = requests.get(url)
    print(re.findall(r'<title>(.*?)</title>', resp.content)[0].decode('utf-8'))
    print('get url <{}> status: {}'.format(url, resp.status_code))

def main():
    urls = [
        'https://python.org/',
        'https://github.com/',
        'https://cn.bing.com/'
    ]
    for url in urls:
        t = threading.Thread(target=get_page, args=(url,))
        t.start()  # 启动线程
    print('end')

if __name__ == '__main__':
    main()
```

2、通过继承Thread类并重写run方法

```python
# coding: utf-8
import re
import threading
import requests

class MyThread(threading.Thread):
    def __init__(self, url):
        super(MyThread, self).__init__()
        self.url = url
    def run(self):
        print('start get {}'.format(self.url))
        resp = requests.get(self.url)
        print(re.findall(r'<title>(.*?)</title>', resp.content)[0].decode('utf-8'))
        print('get url <{}> status: {}'.format(self.url, resp.status_code))

def main():
    urls = [
        'https://python.org/',
        'https://github.com/',
        'https://cn.bing.com/'
    ]
    for url in urls:
        t = MyThread(url)
        t.start()  # 启动线程
    print('end')

if __name__ == '__main__':
    main()
```

Thread对象创建的线程默认不是守护线程，有一个setDaemon方法，传入参数True表示将此线程设为守护线程。将线程设为守护线程后，如果主线程退出了，即使守护线程没有运行完成，那么守护线程也会退出。

如果像设置成守护线程，又不想让守护线程随着主线程的退出而退出，可以使用join()方法。

```python
# coding: utf-8
import re
import threading
import requests

def get_page(url):
    print('start get {}'.format(url))
    resp = requests.get(url)
    print(re.findall(r'<title>(.*?)</title>', resp.content)[0].decode('utf-8'))
    print('get url <{}> status: {}'.format(url, resp.status_code))

def main():
    urls = [
        'https://python.org/',
        'https://github.com/',
        'https://cn.bing.com/'
    ]
    thread_list = [threading.Thread(target=get_page, args=(url,)) for url in urls] 
    for t in thread_list:
        t.setDaemon(True)  # 设置守护线程
        t.start()  # 启动线程
    for t in thread_list:
        t.join()  # 等待线程运行结束
    print('end')

if __name__ == '__main__':
    main()
```

这样主线程就会等所有线程运行完成后才会退出。

如何获取线程运行的返回值：
```python
# coding: utf-8
import re
import time
import threading
import requests

class MyThread(threading.Thread):
    def __init__(self, url):
        super(MyThread, self).__init__()
        self.url = url
    def run(self):
        start_time = time.time()
        print('start get {}'.format(self.url))
        resp = requests.get(self.url)
        print('get url <{}> status: {}'.format(self.url, resp.status_code))
        self.result = time.time() - start_time  # 设置线程函数返回的结果
    def get_result(self):  # 增加返回线程函数调用的结果的方法
        return self.result

def main():
    urls = [
        'https://python.org/',
        'https://github.com/',
        'https://cn.bing.com/'
    ]
    thread_list = [MyThread(url) for url in urls]
    for t in thread_list:
        t.setDaemon(True)  # 设置守护线程
        t.start()  # 启动线程
    for t in thread_list:
        t.join()  # 等待线程运行结束
    for t in thread_list:
        print('url: {}, run time: {}'.format(t.url, t.get_result()))  # 调用方法获取线程返回的结果
    print('end')

if __name__ == '__main__':
    main()
```

线程的创建和销毁时需要占用一定的资源的，所以，假如我们的url不止3个，而是3万个，那么如果每个url都创建一个线程，运行完成后立即销毁，这个也是很耗费资源的。所以一般我们会用线程池来处理。

线程池实现起来很简单，就是构造一个任务队列，启动一些线程一直从任务队列取任务然后执行，知道所有任务完成。

Python中我们可以用multiprocessing.dummy的Pool来创建一个线程池，当然，也可以使用使用第三方包threadpool。

multiprocessing.dummy的Pool虽然在多进程模块multiprocessing下，但是它实际上是线程池，只是操作和multiprocessing的进程池基本一致。

我们来看一下如何使用：
```python
# coding: utf-8
import time
from multiprocessing.dummy import Pool

import requests

def get_page(url):
    start_time = time.time()
    print('start get {}'.format(url))
    resp = requests.get(url)
    print('get url <{}> status: {}'.format(url, resp.status_code))
    return time.time() - start_time

def main():
    urls = [
        'https://python.org/',
        'https://github.com/',
        'https://cn.bing.com/'
    ]
    pool = Pool(2)  # 两个线程的线程池
    res = pool.map(get_page, urls)  # 线程函数执行后的返回值
    pool.close()  # 关闭后不能再向pool中加新的任务
    pool.join()  # 等待所有线程运行完成，一定要先执行close()函数，再执行join()函数
    print(res)

if __name__ == '__main__':
    main()
```

除了map外，还可以使用apply_async、apply、map_async，其中apply_async和map_async是异步的，也就是启动进程函数之后会继续执行后续的代码不用等待进程函数返回。apply_async和map_async方式提供了一写获取进程函数状态的函数：ready()（是否已经启动）、successful()（是否执行成功）、get()（获取执行结果）。

```python
# coding: utf-8
import time
from multiprocessing.dummy import Pool

import requests

def get_page(url):
    start_time = time.time()
    print('start get {}'.format(url))
    resp = requests.get(url)
    print('get url <{}> status: {}'.format(url, resp.status_code))
    return time.time() - start_time

def main():
    urls = [
        'https://python.org/',
        'https://github.com/',
        'https://cn.bing.com/'
    ]
    pool = Pool(2)
    res = pool.map_async(get_page, urls)
    res.wait()  # 等待所有线程函数执行完毕
    if res.ready():  # 线程函数是否已经启动了
        if res.successful():  # 线程函数是否执行成功
            print(res.get())  # 线程函数返回值

if __name__ == '__main__':
    main()
```

今天就介绍到这里。


