# Requests-HTML: HTML Parsing for Humans

今天我们来介绍一下`requests-html`这个库

`requests`是`Python`中一个非常好用的用于发送`HTTP`请求的库，这个库是 *kennethreitz* 的作品，我们之前介绍的Pipenv也是他写的，这次要介绍的`requests-html`也是*kennethreitz*写的。

github地址：https://github.com/kennethreitz/requests-html

`requests-html`是一个处理`HTML`的库，它集成了`requests`,`pyquery`,`fake-useragent`,`bs4`等爬虫常用的库并对他们进行了封装。

安装：
```
pip install requests-html
```
**注意：requests-html只支持Python 3.6及更新的版本。**

#### 简单使用

我们先看下最基本的使用：
```python
>>> from requests_html import HTMLSession
>>> session = HTMLSession()
>>> r = session.get('https://httpbin.org/headers')
>>> print(r.json())
{'headers': {'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Host': 'httpbin.org', 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8'}}
```
如果用`requests`访问的，`User-Agent`是：python-requests/2.21.0，而用`requests_html`访问会用一个正常浏览器的`User-Agent`。
还有一个不同就是`requests_html`的`response`多了个`html`对象。

使用已有的文档构建html对象：
```python
>>> from requests_html import HTML
>>> doc = """<a href='https://httpbin.org'>"""

>>> html = HTML(html=doc)
>>> html.links{'https://httpbin.org'}
```

html对象还有一个pq对象，其实就是PyQuery库创建的一个对象，PyQuery 是 Python 仿照 jQuery 的严格实现。语法与 jQuery 几乎完全相同。如果你对 jQuery 熟悉，那么 PyQuery 来解析文档就是不二之选！

使用`requests_html`访问python.org：
```python
>>> from requests_html import HTMLSession
>>> session = HTMLSession()
>>> r = session.get('https://python.org/')
```

获取所有链接：
```python
>>> r.html.links
# 结果太长，不放了
```

获取绝对路径链接：
```python
>>> r.html.absolute_links
# 结果太长，不放了
```

#### css和XPath选择器的使用

```python
>>> about = r.html.find('#about', first=True)  # first参数为True时会返回第一个元素，否则返回所有元素的列表
```

find方法返回到对象有三个比较常用的属性：
```python
>>> about.html  # 返回元素的html源码
'<li aria-haspopup="true" class="tier-1 element-1" id="about">\n<a class="" href="/about/" title="">About</a>\n<ul aria-hidden="true" class="subnav menu" role="menu">\n<li class="tier-2 element-1" role="treeitem"><a href="/about/apps/" title="">Applications</a></li>\n<li class="tier-2 element-2" role="treeitem"><a href="/about/quotes/" title="">Quotes</a></li>\n<li class="tier-2 element-3" role="treeitem"><a href="/about/gettingstarted/" title="">Getting Started</a></li>\n<li class="tier-2 element-4" role="treeitem"><a href="/about/help/" title="">Help</a></li>\n<li class="tier-2 element-5" role="treeitem"><a href="http://brochure.getpython.info/" title="">Python Brochure</a></li>\n</ul>\n</li>'
>>> about.text  # 返回元素的文本
'About\nApplications\nQuotes\nGetting Started\nHelp\nPython Brochure'
>>> about.attrs  # 元素的所有属性构成的字典
{'aria-haspopup': 'true', 'class': ('tier-1', 'element-1'), 'id': 'about'}
```

XPath选择器也是支持的：
```python
>>> about = r.html.xpath('//*[@id="about"]')[0]
>>> about.text
'About\nApplications\nQuotes\nGetting Started\nHelp\nPython Brochure'
```

#### 使用async

```python
from requests_html import AsyncHTMLSession
asession = AsyncHTMLSession()
async def get_pythonorg():
	r = await asession.get('https://www.python.org/')
	return r

async def get_pypi():
	r = await asession.get('https://pypi.org/')
	return r

async def get_github():
	r = await asession.get('https://github.com/')
	return r

results = asession.run(get_pythonorg, get_pypi, get_github)
# Each item in the results list is a response object and can be interacted with as such
for result in results:
	print(result.html.url)
```

requests-html还支持运行JavaScript以及智能分页，这里就不介绍了，感兴趣的话可以自己去学习。


参考资料：http://html.python-requests.org/

